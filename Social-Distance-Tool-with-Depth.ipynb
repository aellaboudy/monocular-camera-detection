{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Distance Tool with depth\n",
    "\n",
    "This tool combines two algorithms to accurately detect people who are violating the social distancing protocol:\n",
    "- Facebook/Detectron2 (Faster RCNN implementation)`https://github.com/facebookresearch/detectron2`\n",
    "- \"Digging into Self-Supervised Monocular Depth Prediction\" `https://github.com/nianticlabs/monodepth2`\n",
    "\n",
    "**Input:**\n",
    "- A video sequence\n",
    "\n",
    "**Output:**\n",
    "- bounding boxes on all persons detected in the video\n",
    "- highlighing people who are in close proximity\n",
    "- depth map for accurate calculations \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "**Import libraries for Detectron2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m detectron2.utils.collect_env # to check if Detectron2 is working fine\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "from Midas.utils import read_pfm\n",
    "from Midas.run import run\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries and files for MonoDepth2 algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for monodepth2\n",
    "from __future__ import absolute_import, division, print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import PIL.Image as pil\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import monodepth2.networks as networks\n",
    "from monodepth2.utils import download_model_if_doesnt_exist\n",
    "from monodepth2.layers import disp_to_depth\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define key variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_folder = 'frames'\n",
    "result_folder = 'results'\n",
    "depths_folder = 'results/depth'\n",
    "frame_count = 241 # Number of frames to consider in the video (use less for faster calculations) # None will take all frames\n",
    "img_ext = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Video to PNG Frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncap = cv2.VideoCapture(video)\\ncnt=0\\nFPS=cap.get(cv2.CAP_PROP_FPS)\\n# Check if video file is opened successfully\\nif (cap.isOpened()== False): \\n  print(\"Error opening video stream or file\")\\n\\nret,first_frame = cap.read()\\n\\n#Read until video is completed\\nwith tqdm(total=frame_count) as pbar:\\n    while(cap.isOpened()):\\n\\n      # Capture frame-by-frame\\n      ret, frame = cap.read()\\n      pbar.update(1)\\n      if ret == True:\\n\\n        #save each frame to folder        \\n        cv2.imwrite(frames_folder+\\'/{:04d}\\'.format(cnt)+\\'.png\\', frame)\\n        cnt=cnt+1\\n        if(cnt==frame_count) and frame_count != None:\\n          break\\n      # Break the loop\\n      else: \\n        break\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -r $frames_folder/*\n",
    "!mkdir $frames_folder/\n",
    "\n",
    "#specify path to video\n",
    "video = \"onwater_1.m4v\"\n",
    "\n",
    "#capture video\n",
    "cap = cv2.VideoCapture(video)\n",
    "cnt=0\n",
    "FPS=cap.get(cv2.CAP_PROP_FPS)\n",
    "freq = 0.1 #Num of desired seconds\n",
    "# Check if video file is opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "ret,first_frame = cap.read()\n",
    "\n",
    "#Read until video is completed\n",
    "with tqdm(total=frame_count) as pbar:\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "      # Capture frame-by-frame\n",
    "      ret, frame = cap.read()\n",
    "      pbar.update(1)\n",
    "      if ret == True:\n",
    "\n",
    "        #save each frame to folder        \n",
    "        cv2.imwrite(frames_folder+'/{:04d}'.format(cnt)+'.png', frame)\n",
    "        cnt=cnt+FPS*freq\n",
    "        if(cnt==frame_count) and frame_count != None:\n",
    "          break\n",
    "      # Break the loop\n",
    "      else: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading MonoDept2 pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_name = \"mono+stereo_640x192\"\\ndownload_model_if_doesnt_exist(model_name)\\nencoder_path = os.path.join(\"monodepth2/models\", model_name, \"encoder.pth\")\\ndepth_decoder_path = os.path.join(\"monodepth2/models\", model_name, \"depth.pth\")\\n\\n\\n# LOADING PRETRAINED MODEL\\nencoder = networks.ResnetEncoder(18, False)\\nloaded_dict_enc = torch.load(encoder_path, map_location=device)\\nfiltered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in encoder.state_dict()}\\nencoder.load_state_dict(filtered_dict_enc)\\n\\n# extract the height and width of image that this model was trained with\\nfeed_height = loaded_dict_enc[\\'height\\']\\nfeed_width = loaded_dict_enc[\\'width\\']\\n\\n\\nencoder.to(device)\\nencoder.eval();\\n\\n# LOADING PRETRAINED MODEL\\ndepth_decoder = networks.DepthDecoder(num_ch_enc=encoder.num_ch_enc, scales=range(4))\\nloaded_dict = torch.load(depth_decoder_path, map_location=device)\\ndepth_decoder.load_state_dict(loaded_dict)\\n\\ndepth_decoder.to(device)\\ndepth_decoder.eval();\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available(): # and not args.no_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "model_name = \"mono+stereo_640x192\"\n",
    "download_model_if_doesnt_exist(model_name)\n",
    "encoder_path = os.path.join(\"monodepth2/models\", model_name, \"encoder.pth\")\n",
    "depth_decoder_path = os.path.join(\"monodepth2/models\", model_name, \"depth.pth\")\n",
    "\n",
    "\n",
    "# LOADING PRETRAINED MODEL\n",
    "encoder = networks.ResnetEncoder(18, False)\n",
    "loaded_dict_enc = torch.load(encoder_path, map_location=device)\n",
    "filtered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in encoder.state_dict()}\n",
    "encoder.load_state_dict(filtered_dict_enc)\n",
    "\n",
    "# extract the height and width of image that this model was trained with\n",
    "feed_height = loaded_dict_enc['height']\n",
    "feed_width = loaded_dict_enc['width']\n",
    "\n",
    "\n",
    "encoder.to(device)\n",
    "encoder.eval();\n",
    "\n",
    "# LOADING PRETRAINED MODEL\n",
    "depth_decoder = networks.DepthDecoder(num_ch_enc=encoder.num_ch_enc, scales=range(4))\n",
    "loaded_dict = torch.load(depth_decoder_path, map_location=device)\n",
    "depth_decoder.load_state_dict(loaded_dict)\n",
    "\n",
    "depth_decoder.to(device)\n",
    "depth_decoder.eval();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing depth estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDepth(image_path,output_directory,ext):\n",
    "    # FINDING INPUT IMAGES\n",
    "    if os.path.isfile(image_path):\n",
    "        # Only testing on a single image\n",
    "        paths = [image_path]\n",
    "        #output_directory = os.path.dirname(args.image_path)\n",
    "    elif os.path.isdir(image_path):\n",
    "        # Searching folder for images\n",
    "        paths = glob.glob(os.path.join(image_path, '*.{}'.format(ext)))\n",
    "        #output_directory = args.image_path\n",
    "    else:\n",
    "        raise Exception(\"Can not find args.image_path: {}\".format(image_path))\n",
    "    #print(\"-> Predicting on {:d} test images\".format(len(paths)))\n",
    "\n",
    "\n",
    "    # PREDICTING ON EACH IMAGE IN TURN\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(paths)) as pbar:\n",
    "            for idx, image_path in (enumerate(paths)):\n",
    "\n",
    "                if image_path.endswith(\"_disp.jpg\"):\n",
    "                    # don't try to predict disparity for a disparity image!\n",
    "                    continue\n",
    "\n",
    "                # Load image and preprocess\n",
    "                input_image = pil.open(image_path).convert('RGB')\n",
    "                original_width, original_height = input_image.size\n",
    "                input_image = input_image.resize((feed_width, feed_height), pil.LANCZOS)\n",
    "                input_image = transforms.ToTensor()(input_image).unsqueeze(0)\n",
    "\n",
    "                # PREDICTION\n",
    "                input_image = input_image.to(device)\n",
    "                features = encoder(input_image)\n",
    "                outputs = depth_decoder(features)\n",
    "\n",
    "                disp = outputs[(\"disp\", 0)]\n",
    "                disp_resized = torch.nn.functional.interpolate(\n",
    "                    disp, (original_height, original_width), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "                print(\"Output of network resized:\")\n",
    "                print(np.shape(disp_resized))\n",
    "                # Saving numpy file\n",
    "                output_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                name_dest_npy = os.path.join(output_directory, \"{}_disp.npy\".format(output_name))\n",
    "                _, scaled_disp = disp_to_depth(disp, 3.0, 5000)\n",
    "                np.save(name_dest_npy, scaled_disp.cpu().numpy())\n",
    "                \n",
    "                print(\"Absolute depth size:\")\n",
    "                print(np.shape(scaled_disp))\n",
    "                #print(np.shape(disp))\n",
    "                #break\n",
    "                \n",
    "                # Saving colormapped depth image\n",
    "                disp_resized_np = disp_resized.squeeze().cpu().numpy()\n",
    "                \n",
    "                #print(disp_resized_np)\n",
    "                \n",
    "                vmax = np.percentile(disp_resized_np, 95)\n",
    "                normalizer = mpl.colors.Normalize(vmin=disp_resized_np.min(), vmax=vmax)\n",
    "                \n",
    "                mapper = cm.ScalarMappable(norm=normalizer, cmap='magma')\n",
    "                colormapped_im = (mapper.to_rgba(disp_resized_np)[:, :, :3] * 255).astype(np.uint8)\n",
    "                \n",
    "                #print(np.shape(colormapped_im))\n",
    "                #break\n",
    "                \n",
    "                im = pil.fromarray(colormapped_im)\n",
    "                \n",
    "                name_dest_im = os.path.join(output_directory, \"{}_disp.jpeg\".format(output_name))\n",
    "                im.save(name_dest_im)\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘results/depth’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r $depths_folder/*\n",
    "!mkdir $depths_folder\n",
    "run(frames_folder,depths_folder,'model-f6b98070.pt')\n",
    "intrinsic = o3d.io.read_pinhole_camera_intrinsic(\"intrinsics.json\")\n",
    "#findDepth(frames_folder,depths_folder,img_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download a pretrained model from Detectron2 Model Zoo for Faster-RCNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define all the key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function which return the bottom center of every bbox\n",
    "def mid_point(img,img_depth,person,idx):\n",
    "  #get the coordinates\n",
    "  x1,y1,x2,y2 = person[idx]\n",
    "  _ = cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "  \n",
    "  #compute bottom center of bbox\n",
    "  x_mid = int((x1+x2)/2)\n",
    "  y_mid = int(y2)\n",
    "  mid   = (x_mid-1,y_mid-1)\n",
    "  print(\"mid=\",mid)\n",
    "  print(\"img_depth\",img_depth.shape)\n",
    "  z_mid = img_depth[(y_mid-1,x_mid-1)]\n",
    "  mid3d = (x_mid,y_mid,z_mid)\n",
    "    \n",
    "  _ = cv2.circle(img, mid, 5, (0, 0, 255), -1)\n",
    "  cv2.putText(img, str(z_mid) + \" m\", mid, cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "  return mid3d\n",
    "\n",
    "# define a function which computes euclidean distance between two midpoints\n",
    "from scipy.spatial import distance\n",
    "def compute_distance(midpoints,num):\n",
    "  dist = np.zeros((num,num))\n",
    "  for i in range(num):\n",
    "    for j in range(i+1,num):\n",
    "      if i!=j:\n",
    "        dst = distance.euclidean(midpoints[i], midpoints[j])\n",
    "        dist[i][j]=dst\n",
    "  return dist\n",
    "\n",
    "\n",
    "# Finds pairs of people who are close together\n",
    "def find_closest(dist,num,thresh):\n",
    "  p1=[]\n",
    "  p2=[]\n",
    "  d=[]\n",
    "  for i in range(num):\n",
    "    for j in range(i,num):\n",
    "      if( (i!=j) & (dist[i][j]<=thresh)):\n",
    "        p1.append(i)\n",
    "        p2.append(j)\n",
    "        d.append(dist[i][j])\n",
    "  return p1,p2,d\n",
    "\n",
    "\n",
    "# Given pairs of people who are close, color them red\n",
    "def change_2_red(img,img_depth,person,p1,p2):\n",
    "  mid1 = []\n",
    "  mid2 = []\n",
    "  for p in p1:\n",
    "    mid1.append(mid_point(img,img_depth,person,p))\n",
    "  for pp in p2:\n",
    "    mid2.append(mid_point(img,img_depth,person,pp))\n",
    "  for inx in range(len(mid1)):\n",
    "      #print(\"mid1\",mid1[inx][:2])\n",
    "      _ = cv2.line(img, mid1[inx][:2], mid2[inx][:2], (0,255,0), thickness=2, lineType=8, shift=0)\n",
    "  \n",
    "  risky = np.unique(p1+p2)\n",
    "  for i in risky:\n",
    "    x1,y1,x2,y2 = person[i]\n",
    "    _ = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)  \n",
    "  return img\n",
    "\n",
    "\n",
    "# Main function to find closest people\n",
    "def find_closest_people(name,name_depth,thresh,savedir):\n",
    "\n",
    "  img = cv2.imread(name)\n",
    "  depth = np.load(name_depth)\n",
    "  print(\"NPY file shape\")\n",
    "  print(depth.shape)\n",
    "  original_height, original_width,_ = img.shape # (1920,1080) #input_image.size\n",
    "  print(\"Original width, original_height:\")\n",
    "  print(original_width)\n",
    "  print(original_height)\n",
    "  disp_resized = torch.nn.functional.interpolate(\n",
    "                    torch.from_numpy(depth).unsqueeze(0).unsqueeze(0), (original_height, original_width), mode=\"bilinear\", align_corners=False)\n",
    "  img_depth = disp_resized.squeeze().cpu().numpy()\n",
    "\n",
    "  print(\"Depth resized shape, input to algorithms\")\n",
    "  print(disp_resized.shape)\n",
    "  outputs = predictor(img)\n",
    "  classes=outputs['instances'].pred_classes.cpu().numpy()\n",
    "  bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
    "  ind = np.where(classes>-1)[0]\n",
    "  person=bbox[ind]\n",
    "  midpoints = [mid_point(img,img_depth,person,i) for i in range(len(person))]\n",
    "  #num = len(midpoints)\n",
    "  #dist= compute_distance(midpoints,num)\n",
    "  #p1,p2,d=find_closest(dist,num,thresh)\n",
    "  #img = change_2_red(img,img_depth,person,p1,p2)\n",
    "  cv2.imwrite(savedir+'/'+name,img)\n",
    "  #print(savedir+'/'+name)\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch all the frames of the video sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]\n",
    "for file in os.listdir(frames_folder):\n",
    "    if file.endswith(\".png\"):\n",
    "        frames.append(frames_folder+\"/\"+file)\n",
    "frames.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch all the frame depths of the video sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_depths=[]\n",
    "for file in os.listdir(depths_folder):\n",
    "    if file.endswith(\".npy\"):\n",
    "        frame_depths.append(depths_folder+\"/\"+file)\n",
    "frame_depths.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop to get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/242 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awsgui/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:154: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  filter_inds = filter_mask.nonzero()\n",
      "  0%|          | 1/242 [00:08<32:15,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (999, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1683, 752)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1775, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (831, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1688, 742)\n",
      "img_depth (1080, 1920)\n",
      "mid= (321, 644)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1805, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1771, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (311, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (278, 626)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 2/242 [00:16<32:17,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (999, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1680, 753)\n",
      "img_depth (1080, 1920)\n",
      "mid= (830, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1774, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (274, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (321, 644)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1769, 639)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/242 [00:21<27:24,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (997, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1657, 747)\n",
      "img_depth (1080, 1920)\n",
      "mid= (823, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1763, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1799, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (268, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (319, 644)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 4/242 [00:28<26:39,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1621, 750)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1013, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (815, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1055)\n",
      "img_depth (1080, 1920)\n",
      "mid= (314, 644)\n",
      "img_depth (1080, 1920)\n",
      "mid= (260, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1758, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1755, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (815, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (263, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1791, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 5/242 [00:33<24:32,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1058, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1582, 752)\n",
      "img_depth (1080, 1920)\n",
      "mid= (804, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1753, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1748, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (255, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1587, 746)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1062)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 6/242 [00:41<26:28,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1007, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1542, 746)\n",
      "img_depth (1080, 1920)\n",
      "mid= (795, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1547, 745)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1638, 715)\n",
      "img_depth (1080, 1920)\n",
      "mid= (305, 645)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 7/242 [00:48<27:32,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (996, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1510, 754)\n",
      "img_depth (1080, 1920)\n",
      "mid= (786, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1729, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (788, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1514, 750)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 8/242 [00:53<25:06,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1013, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1472, 746)\n",
      "img_depth (1080, 1920)\n",
      "mid= (777, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1474, 752)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 9/242 [00:59<23:28,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (995, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1431, 753)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1440, 752)\n",
      "img_depth (1080, 1920)\n",
      "mid= (768, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1753, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1723, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1717, 639)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 10/242 [01:04<23:06,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1015, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1394, 744)\n",
      "img_depth (1080, 1920)\n",
      "mid= (761, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1401, 753)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1714, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1710, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (286, 644)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1744, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 11/242 [01:11<23:09,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1355, 750)\n",
      "img_depth (1080, 1920)\n",
      "mid= (999, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (752, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1358, 752)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1454, 719)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1737, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1797, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1421, 715)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1701, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1707, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1905, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 12/242 [01:17<23:58,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1314, 759)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1057, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (743, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1790, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1700, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (744, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (152, 603)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 13/242 [01:22<22:35,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1013, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1272, 755)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (734, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1281, 753)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1685, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1374, 719)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1691, 639)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 14/242 [01:28<21:42,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1232, 757)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1018, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (725, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1684, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1713, 633)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1243, 752)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1774, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1677, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1894, 626)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 15/242 [01:34<22:19,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1196, 753)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1018, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (716, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1296, 718)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1674, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1676, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1891, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1199, 751)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1876, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 16/242 [01:41<23:21,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1156, 757)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1023, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1255, 718)\n",
      "img_depth (1080, 1920)\n",
      "mid= (709, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1669, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1890, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1667, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1160, 752)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 17/242 [01:46<22:02,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1117, 757)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1051, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1216, 718)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1663, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (701, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1695, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1120, 751)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1887, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1863, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1655, 637)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 18/242 [01:51<21:10,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1017, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1073, 767)\n",
      "img_depth (1080, 1920)\n",
      "mid= (694, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1656, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1175, 718)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1083, 750)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1687, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1650, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 19/242 [01:56<20:24,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (996, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1041, 755)\n",
      "img_depth (1080, 1920)\n",
      "mid= (687, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1134, 718)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1048, 750)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1650, 640)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1647, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 20/242 [02:01<19:53,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (997, 752)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1024, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1004, 745)\n",
      "img_depth (1080, 1920)\n",
      "mid= (677, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1092, 715)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1642, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1635, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1673, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (100, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 21/242 [02:09<22:14,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1007, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (971, 745)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (956, 746)\n",
      "img_depth (1080, 1920)\n",
      "mid= (669, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1051, 717)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1634, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1626, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1898, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1836, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 22/242 [02:15<21:39,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1024, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1056)\n",
      "img_depth (1080, 1920)\n",
      "mid= (916, 761)\n",
      "img_depth (1080, 1920)\n",
      "mid= (662, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1896, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (932, 746)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1013, 715)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1626, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1830, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1718, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1848, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1905, 653)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 23/242 [02:20<20:45,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1011, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (891, 744)\n",
      "img_depth (1080, 1920)\n",
      "mid= (887, 746)\n",
      "img_depth (1080, 1920)\n",
      "mid= (975, 714)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1902, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1652, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (654, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1621, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1652, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1843, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1619, 639)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 24/242 [02:25<20:12,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1025, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (853, 753)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1894, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (645, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1613, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (938, 714)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1609, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1644, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (856, 745)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1840, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1704, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (215, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1816, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 25/242 [02:30<19:38,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1062, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (814, 748)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1886, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (639, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (821, 743)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1606, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1604, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1826, 628)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 26/242 [02:37<21:13,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1095, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (781, 740)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1883, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (782, 742)\n",
      "img_depth (1080, 1920)\n",
      "mid= (631, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1629, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1598, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (789, 740)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1824, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1592, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 27/242 [02:42<20:24,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1038, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1888, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (752, 743)\n",
      "img_depth (1080, 1920)\n",
      "mid= (745, 740)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1593, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1591, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (624, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1685, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (74, 599)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1798, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1829, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (827, 710)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1624, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1623, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 28/242 [02:48<19:41,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1053, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1880, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (719, 739)\n",
      "img_depth (1080, 1920)\n",
      "mid= (705, 740)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1580, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1586, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1617, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (791, 708)\n",
      "img_depth (1080, 1920)\n",
      "mid= (64, 598)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1823, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 29/242 [02:53<19:09,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1013, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1876, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (679, 742)\n",
      "img_depth (1080, 1920)\n",
      "mid= (680, 738)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1610, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1579, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1609, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1671, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1573, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1802, 631)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 30/242 [02:58<19:28,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1021, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (642, 751)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1880, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (651, 734)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1808, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1571, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1780, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1664, 629)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 31/242 [03:04<19:01,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1044, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1880, 660)\n",
      "img_depth (1080, 1920)\n",
      "mid= (608, 739)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1565, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1563, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1876, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (95, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1599, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (617, 735)\n",
      "img_depth (1080, 1920)\n",
      "mid= (191, 640)\n",
      "img_depth (1080, 1920)\n",
      "mid= (620, 733)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1660, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (666, 696)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 32/242 [03:09<18:39,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1055, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (584, 735)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1874, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1559, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (189, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (635, 693)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1555, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (588, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (588, 734)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1592, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1654, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1766, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1799, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1592, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 33/242 [03:15<19:14,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1463, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1028, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (548, 743)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1871, 657)\n",
      "img_depth (1080, 1920)\n",
      "mid= (585, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (554, 730)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1554, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1549, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (604, 697)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1584, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1647, 629)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 34/242 [03:20<18:45,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1463, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1004, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (528, 734)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1866, 657)\n",
      "img_depth (1080, 1920)\n",
      "mid= (578, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (184, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1544, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1788, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1582, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (529, 727)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 35/242 [03:26<19:28,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1024, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (495, 735)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1867, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (572, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1575, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1545, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (499, 728)\n",
      "img_depth (1080, 1920)\n",
      "mid= (178, 643)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1537, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (542, 694)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1637, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1545, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 36/242 [03:31<18:53,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1045, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (470, 733)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1860, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (174, 640)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1539, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (567, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1532, 633)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1570, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1631, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1779, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1864, 652)\n",
      "img_depth (1080, 1920)\n",
      "mid= (468, 728)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 37/242 [03:36<18:26,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (442, 728)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1024, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1859, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (563, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1627, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1765, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1862, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1565, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1528, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (442, 723)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 38/242 [03:42<18:16,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (414, 731)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1009, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1862, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (558, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1529, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1624, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1860, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (62, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1562, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1527, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1560, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (418, 723)\n",
      "img_depth (1080, 1920)\n",
      "mid= (418, 721)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 39/242 [03:47<17:54,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1463, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (391, 730)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1019, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (553, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1857, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1853, 648)\n",
      "img_depth (1080, 1920)\n",
      "mid= (175, 643)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1522, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 40/242 [03:52<17:38,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (364, 726)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1008, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1859, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1523, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (175, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (551, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1860, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1517, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1616, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1763, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (368, 723)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1554, 635)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 41/242 [03:57<17:26,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (343, 726)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1002, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1857, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (546, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1514, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (176, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1614, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1856, 646)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1519, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1553, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1761, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1551, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 42/242 [04:02<17:19,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1023, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (320, 715)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1855, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (316, 725)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1509, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (543, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (175, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1854, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1547, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1515, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1755, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (355, 686)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 43/242 [04:08<17:22,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (299, 744)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1011, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (539, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1852, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1546, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1850, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (298, 722)\n",
      "img_depth (1080, 1920)\n",
      "mid= (172, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1514, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1604, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1506, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1751, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (334, 688)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 44/242 [04:16<20:14,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (276, 730)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1848, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1028, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (539, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1508, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1845, 651)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1512, 640)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1741, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1502, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1542, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (276, 716)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1752, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1604, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1540, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 45/242 [04:21<19:10,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (256, 722)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1008, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1849, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (535, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1844, 657)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1538, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1501, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (257, 710)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1600, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1508, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 46/242 [04:26<18:23,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1009, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1849, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (235, 718)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (533, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1506, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1848, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1499, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (240, 710)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1538, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1599, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1746, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 47/242 [04:33<19:33,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1000, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1846, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (221, 709)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (531, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1844, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1504, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1535, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1503, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1740, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1536, 634)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 48/242 [04:38<18:36,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (199, 706)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (996, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1842, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (528, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1501, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1593, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1844, 650)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1498, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1536, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (228, 677)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 49/242 [04:43<17:56,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (179, 706)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1500, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1843, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1003, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (528, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1841, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1592, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1534, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1533, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1740, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 50/242 [04:51<19:57,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1464, 1062)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1004, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (158, 706)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1844, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (524, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (168, 699)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1844, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1590, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1492, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1530, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1738, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1496, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1706, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1553, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1528, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 51/242 [04:59<21:38,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (155, 699)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1013, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1840, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (523, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1496, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1838, 651)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1529, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1492, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1587, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1737, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██▏       | 52/242 [05:04<20:01,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (128, 707)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1065, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1841, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1495, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1487, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (522, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1837, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1734, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1839, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1527, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1585, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1730, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (522, 618)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1525, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 53/242 [05:12<21:11,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (112, 700)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1062, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1838, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (518, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1841, 657)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1485, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1493, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1732, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (115, 696)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1582, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1524, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1523, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1701, 628)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 54/242 [05:18<20:34,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1064, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1839, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (99, 697)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (518, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (98, 696)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1582, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1841, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1731, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1490, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1524, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1491, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 55/242 [05:23<19:08,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (84, 693)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1061, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (516, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1837, 657)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1832, 658)\n",
      "img_depth (1080, 1920)\n",
      "mid= (84, 693)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1482, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1732, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 56/242 [05:29<18:33,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1464, 1056)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1009, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (67, 700)\n",
      "img_depth (1080, 1920)\n",
      "mid= (516, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1838, 655)\n",
      "img_depth (1080, 1920)\n",
      "mid= (69, 692)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1839, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1580, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (516, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1519, 636)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 57/242 [05:34<17:53,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1019, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1838, 656)\n",
      "img_depth (1080, 1920)\n",
      "mid= (513, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (58, 689)\n",
      "img_depth (1080, 1920)\n",
      "mid= (62, 697)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1838, 657)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1488, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1518, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1733, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1694, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1575, 631)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 58/242 [05:40<17:14,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1008, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (49, 689)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1837, 652)\n",
      "img_depth (1080, 1920)\n",
      "mid= (54, 689)\n",
      "img_depth (1080, 1920)\n",
      "mid= (511, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1694, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1836, 650)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1516, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1485, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1575, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1714, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1477, 637)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 59/242 [05:45<16:45,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1018, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (41, 687)\n",
      "img_depth (1080, 1920)\n",
      "mid= (509, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1832, 652)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1693, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1481, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (511, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1833, 650)\n",
      "img_depth (1080, 1920)\n",
      "mid= (42, 693)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1709, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1514, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1570, 632)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 60/242 [05:52<18:14,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (34, 684)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1050, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1831, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (508, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1710, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1830, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1474, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 61/242 [05:57<17:20,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1463, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1020, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (28, 682)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1831, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (507, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1481, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1834, 651)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1712, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1716, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1689, 626)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 62/242 [06:05<18:46,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1018, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1828, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (506, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1480, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1569, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1834, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (21, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1513, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1474, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1711, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1689, 626)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 63/242 [06:10<17:40,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1058, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (506, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1833, 651)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1479, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1511, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1479, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (14, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1828, 651)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1470, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1717, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1533, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1570, 628)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▋       | 64/242 [06:15<16:50,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1058, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1828, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (506, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1829, 652)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1479, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1719, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1569, 628)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 65/242 [06:20<16:14,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1064, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1826, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (504, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1827, 652)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1479, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1718, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1705, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1508, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1685, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1564, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 66/242 [06:25<15:47,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1038, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1825, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (502, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1823, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1718, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1506, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1477, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1684, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1566, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1468, 635)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 67/242 [06:30<15:25,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1033, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1832, 657)\n",
      "img_depth (1080, 1920)\n",
      "mid= (516, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1693, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1834, 656)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 68/242 [06:35<15:09,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1006, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1463, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1854, 658)\n",
      "img_depth (1080, 1920)\n",
      "mid= (541, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1851, 663)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1505, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1719, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1542, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 69/242 [06:40<14:58,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1039, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1864, 652)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1753, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (579, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1779, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1638, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1541, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1771, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1861, 658)\n",
      "img_depth (1080, 1920)\n",
      "mid= (9, 673)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1602, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (579, 622)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 70/242 [06:45<14:46,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1033, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (22, 674)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1885, 651)\n",
      "img_depth (1080, 1920)\n",
      "mid= (627, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (626, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1587, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1622, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1682, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 71/242 [06:50<14:36,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1045, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (38, 673)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1635, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (680, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1838, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1866, 628)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 72/242 [06:57<16:00,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (63, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1025, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (741, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1898, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1690, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (386, 654)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 73/242 [07:03<16:11,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (105, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1017, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (805, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1746, 633)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 74/242 [07:08<15:27,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (153, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1037, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (871, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (260, 611)\n",
      "img_depth (1080, 1920)\n",
      "mid= (157, 677)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 75/242 [07:13<15:02,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1041, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (202, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (938, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (208, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (308, 611)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 76/242 [07:18<14:35,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1030, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (258, 682)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1006, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 77/242 [07:23<14:12,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1006, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (310, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1076, 629)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 78/242 [07:28<14:05,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1040, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (367, 681)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1144, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (370, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (368, 677)\n",
      "img_depth (1080, 1920)\n",
      "mid= (789, 661)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 79/242 [07:33<13:48,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1024, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (424, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1215, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (428, 677)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 80/242 [07:39<13:56,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1023, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (484, 677)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1284, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (697, 641)\n",
      "img_depth (1080, 1920)\n",
      "mid= (772, 646)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 81/242 [07:44<13:40,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1019, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (544, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1353, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (548, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (837, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (770, 1069)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 82/242 [07:49<13:27,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1014, 1069)\n",
      "img_depth (1080, 1920)\n",
      "mid= (607, 674)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1419, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (610, 676)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 83/242 [07:54<13:17,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1021, 1069)\n",
      "img_depth (1080, 1920)\n",
      "mid= (671, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (675, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1487, 631)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▍      | 84/242 [07:58<13:09,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1005, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (737, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (733, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1554, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1132, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 85/242 [08:04<13:15,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (991, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (802, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (798, 686)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1617, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1461, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1203, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1053, 645)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 86/242 [08:11<15:11,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (983, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (859, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1678, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (864, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (879, 623)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 87/242 [08:17<15:13,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1007, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (927, 676)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 88/242 [08:24<15:24,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1004, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (985, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1797, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (987, 678)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 89/242 [08:29<15:09,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (992, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1047, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1374, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1851, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1047, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1375, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1567, 663)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 90/242 [08:37<15:56,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1463, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (960, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1107, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1101, 685)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1903, 623)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 91/242 [08:42<15:23,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1465, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (985, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1160, 677)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1686, 662)\n",
      "img_depth (1080, 1920)\n",
      "mid= (291, 603)\n",
      "img_depth (1080, 1920)\n",
      "mid= (787, 1074)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 92/242 [08:47<14:27,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1464, 1060)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1004, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1216, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1223, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (344, 603)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 93/242 [08:55<16:00,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (997, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1058)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1275, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (402, 606)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1282, 646)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1802, 662)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1281, 676)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 94/242 [09:02<16:21,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1005, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1333, 674)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1340, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1857, 659)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 95/242 [09:07<15:05,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1048, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1392, 677)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1059)\n",
      "img_depth (1080, 1920)\n",
      "mid= (513, 607)\n",
      "img_depth (1080, 1920)\n",
      "mid= (795, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1883, 607)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███▉      | 96/242 [09:14<15:01,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1028, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1450, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1451, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1783, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (811, 1072)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 97/242 [09:19<14:00,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1033, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1502, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1057)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 98/242 [09:24<13:22,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1038, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1562, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1559, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1462, 1056)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 99/242 [09:29<12:51,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1024, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1609, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1612, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1161, 613)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 100/242 [09:37<14:37,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1039, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1655, 673)\n",
      "img_depth (1080, 1920)\n",
      "mid= (778, 1073)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 101/242 [09:42<13:40,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1035, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1703, 680)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1708, 674)\n",
      "img_depth (1080, 1920)\n",
      "mid= (111, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (844, 615)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1272, 614)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 102/242 [09:46<12:57,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1030, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1756, 680)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1757, 677)\n",
      "img_depth (1080, 1920)\n",
      "mid= (898, 617)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 103/242 [09:51<12:27,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1805, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1053, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (209, 597)\n",
      "img_depth (1080, 1920)\n",
      "mid= (955, 613)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 104/242 [09:58<13:01,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (978, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1856, 673)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1011, 617)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 105/242 [10:05<14:09,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1045, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1885, 674)\n",
      "img_depth (1080, 1920)\n",
      "mid= (296, 603)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1049, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1885, 676)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 106/242 [10:10<13:13,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1082, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1894, 677)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1063, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (311, 603)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 107/242 [10:18<14:34,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1027, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (320, 602)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1901, 673)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1902, 674)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1072, 619)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 108/242 [10:23<13:26,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1077, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (319, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1073, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1905, 675)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1529, 616)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 109/242 [10:28<12:38,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1059, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (319, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1909, 674)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1069, 619)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1530, 615)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 110/242 [10:33<12:01,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1187, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (312, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1060, 620)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 111/242 [10:41<13:33,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1181, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (310, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1053, 619)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 112/242 [10:46<12:38,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1189, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (300, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1044, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (768, 1073)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 113/242 [10:54<13:54,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1040, 1068)\n",
      "img_depth (1080, 1920)\n",
      "mid= (295, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1035, 619)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 114/242 [10:59<12:46,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1078, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1023, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (284, 599)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 115/242 [11:04<11:59,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1077, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (278, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1013, 621)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 116/242 [11:09<11:28,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1200, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (270, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1002, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1522, 617)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 117/242 [11:14<11:03,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1082, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (989, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (260, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 118/242 [11:19<10:43,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1049, 1069)\n",
      "img_depth (1080, 1920)\n",
      "mid= (973, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (244, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 119/242 [11:23<10:27,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1200, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (956, 622)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████▉     | 120/242 [11:28<10:16,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1241, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (939, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (215, 599)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 121/242 [11:36<11:53,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1112, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (916, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (196, 598)\n",
      "img_depth (1080, 1920)\n",
      "mid= (271, 598)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 122/242 [11:44<13:03,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1020, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (898, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (183, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 123/242 [11:49<11:59,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1087, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (876, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (164, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 124/242 [11:56<12:36,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1026, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (858, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (146, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1470, 616)\n",
      "img_depth (1080, 1920)\n",
      "mid= (865, 823)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 125/242 [12:04<13:08,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1078, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (845, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (141, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 126/242 [12:11<13:20,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (839, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1198, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (146, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (379, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 127/242 [12:16<12:04,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (837, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1079, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (144, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (385, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 128/242 [12:23<12:25,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (832, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1199, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (149, 599)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1014, 604)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 129/242 [12:29<12:09,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (822, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1196, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (154, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (390, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 130/242 [12:34<11:11,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1075, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (808, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (135, 597)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1018, 603)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 131/242 [12:39<10:30,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (787, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1112, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (128, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 132/242 [12:44<10:01,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (767, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1204, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (109, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 133/242 [12:49<09:39,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (741, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1087, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (104, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1534, 614)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 134/242 [12:57<11:00,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (715, 633)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1097, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (89, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1534, 616)\n",
      "img_depth (1080, 1920)\n",
      "mid= (344, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 135/242 [13:02<10:18,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (689, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1087, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (337, 598)\n",
      "img_depth (1080, 1920)\n",
      "mid= (866, 826)\n",
      "img_depth (1080, 1920)\n",
      "mid= (79, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 136/242 [13:08<10:21,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (665, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1035, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1590, 617)\n",
      "img_depth (1080, 1920)\n",
      "mid= (66, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 137/242 [13:13<09:47,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (636, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1120, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (54, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1530, 617)\n",
      "img_depth (1080, 1920)\n",
      "mid= (319, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 138/242 [13:18<09:21,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1136, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (603, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (46, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 139/242 [13:25<10:03,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (570, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1089, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1590, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1522, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (302, 599)\n",
      "img_depth (1080, 1920)\n",
      "mid= (39, 597)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 140/242 [13:31<09:45,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (534, 646)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1081, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1525, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1590, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (287, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (31, 599)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 141/242 [13:37<10:07,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (492, 645)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1016, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1513, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 142/242 [13:44<10:39,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (450, 647)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1209, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (265, 598)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1485, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1519, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (951, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1000, 602)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 143/242 [13:50<09:52,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (407, 648)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1042, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1516, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (944, 603)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 144/242 [13:54<09:16,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (356, 647)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1051, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1508, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1487, 617)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████▉    | 145/242 [13:59<08:51,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (306, 647)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1065, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1562, 621)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 146/242 [14:05<08:33,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (251, 650)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1070, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1501, 623)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 147/242 [14:11<08:58,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (194, 651)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1208, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (202, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 148/242 [14:19<09:55,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (140, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1209, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (914, 602)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 149/242 [14:25<09:56,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (76, 658)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1236, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1521, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (126, 594)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1597, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (910, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (183, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1596, 621)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 150/242 [14:30<09:11,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1047, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (31, 662)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1520, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (177, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 151/242 [14:35<08:37,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1097, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (170, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1605, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1525, 627)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 152/242 [14:43<09:33,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1085, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1535, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (163, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1618, 621)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1542, 622)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 153/242 [14:48<08:49,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1102, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1545, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (156, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 154/242 [14:54<08:35,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1093, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (147, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 155/242 [15:00<08:26,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1126, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1559, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (142, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 156/242 [15:05<07:57,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1053, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (132, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1566, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (254, 594)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1572, 627)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 157/242 [15:10<07:36,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1033, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (128, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1658, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1579, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1844, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1659, 622)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 158/242 [15:15<07:20,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1059, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1667, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (119, 595)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 159/242 [15:20<07:08,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1039, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (113, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1683, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1594, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1594, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 160/242 [15:25<06:59,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1024, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1613, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1693, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (107, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1564, 622)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 161/242 [15:33<08:04,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1090, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (241, 594)\n",
      "img_depth (1080, 1920)\n",
      "mid= (97, 596)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1707, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1782, 623)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1625, 627)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 162/242 [15:41<08:49,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1137, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1641, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1722, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (93, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1715, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1874, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1637, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1796, 624)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 163/242 [15:48<08:53,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1063, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1727, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1647, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1731, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1810, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1883, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1650, 629)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 164/242 [15:54<08:31,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1031, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1750, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1659, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1822, 625)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1745, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1887, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (156, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1665, 629)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 165/242 [15:59<07:48,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1095, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1761, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1681, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1688, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1761, 624)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▊   | 166/242 [16:04<07:16,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1067, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1699, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1784, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1779, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (145, 598)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 167/242 [16:12<07:56,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1016, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1714, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1796, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1715, 629)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 168/242 [16:17<07:20,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1068, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1733, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1736, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1812, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1888, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1813, 626)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████▉   | 169/242 [16:22<06:52,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1054, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1753, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1753, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1834, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1833, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1897, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 170/242 [16:27<06:40,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1071, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1768, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (162, 595)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1770, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1848, 628)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 171/242 [16:32<06:22,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1065, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1786, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1869, 627)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1872, 628)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 172/242 [16:40<07:09,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1048, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1800, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1800, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1879, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1879, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████▏  | 173/242 [16:48<07:37,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1088, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1820, 633)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1888, 628)\n",
      "img_depth (1080, 1920)\n",
      "mid= (156, 597)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1886, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1180, 601)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 174/242 [16:53<06:58,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (42, 806)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1113, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1832, 633)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1894, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (150, 598)\n",
      "img_depth (1080, 1920)\n",
      "mid= (982, 603)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1894, 630)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1763, 622)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1835, 633)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 175/242 [16:58<06:28,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (98, 806)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1852, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1076, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1850, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (983, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (131, 598)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 176/242 [17:03<06:08,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1102, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (193, 791)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1865, 636)\n",
      "img_depth (1080, 1920)\n",
      "mid= (135, 597)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 177/242 [17:08<06:06,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (285, 760)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1100, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1873, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1873, 635)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▎  | 178/242 [17:13<05:47,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1084, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1878, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (356, 739)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1878, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 179/242 [17:18<05:32,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (415, 735)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1096, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1892, 633)\n",
      "img_depth (1080, 1920)\n",
      "mid= (101, 598)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 180/242 [17:23<05:24,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (468, 721)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1076, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1897, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (972, 601)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▍  | 181/242 [17:30<05:37,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1069, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (518, 710)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1742, 627)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 182/242 [17:35<05:27,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1086, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (556, 703)\n",
      "img_depth (1080, 1920)\n",
      "mid= (76, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 183/242 [17:40<05:13,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1056, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (592, 693)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1761, 629)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 184/242 [17:48<05:49,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1056, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1769, 624)\n",
      "img_depth (1080, 1920)\n",
      "mid= (627, 690)\n",
      "img_depth (1080, 1920)\n",
      "mid= (610, 724)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▋  | 185/242 [17:55<06:15,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1133, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (661, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (654, 708)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 186/242 [18:01<05:47,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (693, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1044, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (927, 602)\n",
      "img_depth (1080, 1920)\n",
      "mid= (686, 703)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 187/242 [18:07<05:46,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1112, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (711, 676)\n",
      "img_depth (1080, 1920)\n",
      "mid= (706, 698)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1759, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 188/242 [18:14<05:52,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (715, 689)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1046, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1742, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (883, 606)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1899, 645)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 189/242 [18:19<05:21,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1073, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (726, 679)\n",
      "img_depth (1080, 1920)\n",
      "mid= (726, 686)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1764, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▊  | 190/242 [18:24<04:58,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1048, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (745, 672)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1787, 619)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 191/242 [18:29<04:41,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1060, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (766, 670)\n",
      "img_depth (1080, 1920)\n",
      "mid= (765, 678)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1050, 602)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1757, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (838, 605)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 192/242 [18:34<04:30,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1036, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (772, 663)\n",
      "img_depth (1080, 1920)\n",
      "mid= (774, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (772, 668)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1906, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1754, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (815, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 193/242 [18:41<04:48,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1023, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1745, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (779, 658)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1798, 626)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1866, 634)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 194/242 [18:47<04:33,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1013, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1729, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (770, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (790, 658)\n",
      "img_depth (1080, 1920)\n",
      "mid= (791, 648)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1727, 639)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 195/242 [18:53<04:42,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1085, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (961, 602)\n",
      "img_depth (1080, 1920)\n",
      "mid= (793, 663)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1087, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 196/242 [18:59<04:27,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1047, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (811, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (809, 662)\n",
      "img_depth (1080, 1920)\n",
      "mid= (737, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (797, 671)\n",
      "img_depth (1080, 1920)\n",
      "mid= (959, 599)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 197/242 [19:04<04:19,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1033, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (812, 652)\n",
      "img_depth (1080, 1920)\n",
      "mid= (718, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (809, 654)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1726, 646)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 198/242 [19:12<04:43,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1225, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1713, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (810, 640)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1864, 649)\n",
      "img_depth (1080, 1920)\n",
      "mid= (812, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (913, 602)\n",
      "img_depth (1080, 1920)\n",
      "mid= (691, 602)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 199/242 [19:20<04:52,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1035, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (814, 649)\n",
      "img_depth (1080, 1920)\n",
      "mid= (821, 650)\n",
      "img_depth (1080, 1920)\n",
      "mid= (680, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1722, 630)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 200/242 [19:26<04:28,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1245, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (822, 638)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1728, 641)\n",
      "img_depth (1080, 1920)\n",
      "mid= (827, 642)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 201/242 [19:33<04:37,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1235, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1726, 644)\n",
      "img_depth (1080, 1920)\n",
      "mid= (818, 633)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 202/242 [19:40<04:25,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1058, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (815, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (631, 603)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1753, 633)\n",
      "img_depth (1080, 1920)\n",
      "mid= (853, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (817, 641)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1695, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1804, 631)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 203/242 [19:46<04:20,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1051, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1734, 639)\n",
      "img_depth (1080, 1920)\n",
      "mid= (814, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1804, 637)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 204/242 [19:52<04:04,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1039, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (817, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1727, 647)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 205/242 [19:57<03:41,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1044, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (593, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1884, 653)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1744, 643)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 206/242 [20:04<03:40,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1021, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1880, 646)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1715, 634)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1775, 638)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 207/242 [20:10<03:34,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1042, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1731, 637)\n",
      "img_depth (1080, 1920)\n",
      "mid= (821, 635)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1786, 644)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 208/242 [20:15<03:18,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1026, 1072)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 209/242 [20:21<03:18,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1051, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1772, 650)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1878, 642)\n",
      "img_depth (1080, 1920)\n",
      "mid= (830, 625)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 210/242 [20:26<03:02,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1059, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1788, 647)\n",
      "img_depth (1080, 1920)\n",
      "mid= (551, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (833, 624)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 211/242 [20:31<02:49,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1188, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1815, 647)\n",
      "img_depth (1080, 1920)\n",
      "mid= (793, 600)\n",
      "img_depth (1080, 1920)\n",
      "mid= (843, 631)\n",
      "img_depth (1080, 1920)\n",
      "mid= (552, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 212/242 [20:36<02:39,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1044, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1798, 644)\n",
      "img_depth (1080, 1920)\n",
      "mid= (855, 620)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1821, 650)\n",
      "img_depth (1080, 1920)\n",
      "mid= (793, 597)\n",
      "img_depth (1080, 1920)\n",
      "mid= (551, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 213/242 [20:41<02:30,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1078, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (854, 632)\n",
      "img_depth (1080, 1920)\n",
      "mid= (535, 601)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1818, 645)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1839, 646)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 214/242 [20:46<02:23,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1217, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1852, 646)\n",
      "img_depth (1080, 1920)\n",
      "mid= (519, 603)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 215/242 [20:51<02:16,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1863, 647)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1034, 1071)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 216/242 [20:56<02:10,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1033, 1070)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1871, 647)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 217/242 [21:02<02:12,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1124, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1881, 646)\n",
      "img_depth (1080, 1920)\n",
      "mid= (545, 602)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 218/242 [21:07<02:04,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1054, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1894, 648)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 219/242 [21:12<01:57,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1195, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (552, 600)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 220/242 [21:17<01:51,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1029, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (581, 601)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████▏| 221/242 [21:22<01:45,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1040, 1071)\n",
      "img_depth (1080, 1920)\n",
      "mid= (920, 617)\n",
      "img_depth (1080, 1920)\n",
      "mid= (248, 598)\n",
      "img_depth (1080, 1920)\n",
      "mid= (369, 599)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 222/242 [21:28<01:50,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1235, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (562, 601)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 223/242 [21:33<01:41,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1035, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (564, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (941, 629)\n",
      "img_depth (1080, 1920)\n",
      "mid= (541, 603)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 224/242 [21:38<01:35,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1067, 1076)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 225/242 [21:45<01:38,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1110, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (939, 615)\n",
      "img_depth (1080, 1920)\n",
      "mid= (959, 621)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 226/242 [21:50<01:28,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1195, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (380, 596)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 227/242 [21:55<01:20,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1055, 1073)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 228/242 [22:02<01:19,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1017, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (944, 616)\n",
      "img_depth (1080, 1920)\n",
      "mid= (577, 605)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 229/242 [22:08<01:14,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1057, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (595, 603)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1237, 606)\n",
      "img_depth (1080, 1920)\n",
      "mid= (957, 613)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 230/242 [22:14<01:10,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1044, 1073)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 231/242 [22:19<01:01,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1050, 1074)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 232/242 [22:25<00:58,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1055, 1074)\n",
      "img_depth (1080, 1920)\n",
      "mid= (591, 605)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 233/242 [22:30<00:50,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1090, 1075)\n",
      "img_depth (1080, 1920)\n",
      "mid= (598, 604)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 234/242 [22:35<00:43,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1038, 1073)\n",
      "img_depth (1080, 1920)\n",
      "mid= (708, 606)\n",
      "img_depth (1080, 1920)\n",
      "mid= (606, 605)\n",
      "img_depth (1080, 1920)\n",
      "mid= (642, 605)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 235/242 [22:40<00:36,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (210, 891)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1053, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1004, 613)\n",
      "img_depth (1080, 1920)\n",
      "mid= (614, 604)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 236/242 [22:45<00:31,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (435, 832)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1053, 1072)\n",
      "img_depth (1080, 1920)\n",
      "mid= (429, 797)\n",
      "img_depth (1080, 1920)\n",
      "mid= (622, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1013, 614)\n",
      "img_depth (1080, 1920)\n",
      "mid= (445, 799)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 237/242 [22:50<00:25,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1206, 1077)\n",
      "img_depth (1080, 1920)\n",
      "mid= (608, 793)\n",
      "img_depth (1080, 1920)\n",
      "mid= (611, 768)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 238/242 [22:55<00:20,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1193, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (729, 765)\n",
      "img_depth (1080, 1920)\n",
      "mid= (747, 746)\n",
      "img_depth (1080, 1920)\n",
      "mid= (638, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (759, 756)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 239/242 [23:02<00:17,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1191, 1079)\n",
      "img_depth (1080, 1920)\n",
      "mid= (847, 741)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1029, 615)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 240/242 [23:08<00:11,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1080, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (933, 728)\n",
      "img_depth (1080, 1920)\n",
      "mid= (835, 605)\n",
      "img_depth (1080, 1920)\n",
      "mid= (650, 605)\n",
      "img_depth (1080, 1920)\n",
      "mid= (701, 605)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1034, 616)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████▉| 241/242 [23:13<00:05,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1184, 1078)\n",
      "img_depth (1080, 1920)\n",
      "mid= (997, 713)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1036, 618)\n",
      "img_depth (1080, 1920)\n",
      "mid= (654, 608)\n",
      "img_depth (1080, 1920)\n",
      "mid= (681, 609)\n",
      "img_depth (1080, 1920)\n",
      "NPY file shape\n",
      "(1080, 1920)\n",
      "Original width, original_height:\n",
      "1920\n",
      "1080\n",
      "Depth resized shape, input to algorithms\n",
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [23:18<00:00,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid= (1082, 1076)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1033, 618)\n",
      "img_depth (1080, 1920)\n",
      "mid= (654, 604)\n",
      "img_depth (1080, 1920)\n",
      "mid= (1048, 701)\n",
      "img_depth (1080, 1920)\n",
      "mid= (757, 605)\n",
      "img_depth (1080, 1920)\n",
      "mid= (680, 605)\n",
      "img_depth (1080, 1920)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#from tqdm import tqdm\n",
    "thresh=110\n",
    "with tqdm(total=len(frames)) as pbar:\n",
    "    for i in range(len(frames)):\n",
    "        find_closest_people(frames[i],frame_depths[i],thresh,result_folder)\n",
    "        pbar.update(1)\n",
    "    \n",
    "#_ = [find_closest_people(frames[i],thresh,'frames2') for i in tqdm(range(len(frames))) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main file with highlighed results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [00:10<00:00, 23.53it/s]\n",
      "100%|██████████| 242/242 [00:05<00:00, 44.04it/s]\n"
     ]
    }
   ],
   "source": [
    "frames=[]\n",
    "for file in os.listdir(result_folder+\"/frames/\"):\n",
    "    if file.endswith(\".png\"):\n",
    "        frames.append(file)\n",
    "frames.sort()\n",
    "\n",
    "frame_array=[]\n",
    "with tqdm(total=len(frames)) as pbar:\n",
    "    for i in range(len(frames)):\n",
    "\n",
    "        #reading each files\n",
    "        img = cv2.imread(result_folder+'/frames/'+frames[i])\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    "        pbar.update(1)\n",
    "\n",
    "out = cv2.VideoWriter(result_folder+'/result.mp4',cv2.VideoWriter_fourcc(*'DIVX'), FPS, size)\n",
    " \n",
    "with tqdm(total=len(frames)) as pbar:\n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "        pbar.update(1)\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depth map video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "frames_depth=[]\n",
    "for file in os.listdir(depths_folder):\n",
    "    if file.endswith(\".png\"):\n",
    "        frames_depth.append(file)\n",
    "frames_depth.sort()\n",
    "\n",
    "frame_array=[]\n",
    "with tqdm(total=len(frames_depth)) as pbar:\n",
    "    for i in range(len(frames_depth)):\n",
    "\n",
    "        #reading each files\n",
    "        img = cv2.imread(depths_folder+'/'+frames_depth[i])\n",
    "        #img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    "        pbar.update(1)\n",
    "\n",
    "out = cv2.VideoWriter(result_folder+'/depth_result.mp4',cv2.VideoWriter_fourcc(*'DIVX'), FPS, size)\n",
    " \n",
    "with tqdm(total=len(frames_depth)) as pbar:\n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "        pbar.update(1)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
